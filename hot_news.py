import requests
import smtplib
import os
import re
import json
from email.mime.text import MIMEText
from datetime import datetime
from bs4 import BeautifulSoup
import time

# ==================== æ–°é—»æºå‡½æ•°æ›´æ–° ====================

def get_people_daily():
    """è·å–äººæ°‘ç½‘æ—¶æ”¿è¦é—» - æƒå¨å®˜æ–¹æº[citation:1][citation:6]"""
    try:
        url = "http://www.people.com.cn/rss/politics.xml"
        response = requests.get(url, timeout=20, headers=HEADERS)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'xml')
            items = soup.find_all('item')[:5]  # å–å‰5æ¡
            news_list = []
            for item in items:
                title = item.title.text.strip() if item.title else ""
                if title:
                    # æ¸…ç†æ ‡é¢˜
                    title = re.sub(r'<.*?>|&nbsp;|&amp;', ' ', title)
                    news_list.append((title, ""))
            return "ğŸ“° äººæ°‘ç½‘æ—¶æ”¿è¦é—»", news_list
    except Exception as e:
        print(f"äººæ°‘ç½‘è·å–å¤±è´¥: {e}")
    return None

def get_baidu_hot():
    """è·å–ç™¾åº¦çƒ­æœæ¦œ"""
    try:
        # ä½¿ç”¨æ›´ç¨³å®šçš„é€šç”¨æ–°é—»APIï¼Œå¹¶ç­›é€‰å‰5æ¡[citation:4]
        url = "https://api.oioweb.cn/api/news/hot"
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            data = response.json()
            if 'result' in data:
                news_list = []
                for item in data['result'][:5]:
                    title = item.get('title', '').strip()
                    hot = item.get('hot', '')
                    if title:
                        news_list.append((title, hot))
                return "ğŸ” ç™¾åº¦å®æ—¶çƒ­æœ", news_list
    except Exception as e:
        print(f"ç™¾åº¦çƒ­æœè·å–å¤±è´¥: {e}")
    return None

def get_today_hotlist():
    """è·å–ä»Šæ—¥çƒ­æ¦œ - å¤šå¹³å°èšåˆçƒ­ç‚¹[citation:7]"""
    try:
        # ä½¿ç”¨èšåˆAPIè·å–ç»¼åˆçƒ­ç‚¹
        url = "https://api.oioweb.cn/api/news"
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            data = response.json()
            if 'result' in data:
                news_list = []
                for item in data['result'][:5]:
                    title = item.get('title', '').strip()
                    if title:
                        news_list.append((title, item.get('hot', '')))
                return "ğŸ“ˆ ä»Šæ—¥çƒ­æ¦œ", news_list
    except Exception as e:
        print(f"ä»Šæ—¥çƒ­æ¦œè·å–å¤±è´¥: {e}")
    return None

def get_sina_news():
    """è·å–æ–°æµªæ–°é—»çƒ­ç‚¹[citation:3][citation:8]"""
    try:
        # å°è¯•è·å–æ–°æµªè¦é—»
        url = "https://api.oioweb.cn/api/news"
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            data = response.json()
            if 'result' in data:
                news_list = []
                count = 0
                # ä»é€šç”¨æ–°é—»ä¸­å–å‰5æ¡ä½œä¸ºæ–°æµªçƒ­ç‚¹
                for item in data['result']:
                    if count >= 5:
                        break
                    title = item.get('title', '').strip()
                    if title and any(word in title for word in ['æ–°æµª', 'å›½é™…', 'è´¢ç»']):
                        news_list.append((title, item.get('hot', '')))
                        count += 1
                if news_list:
                    return "ğŸ†• æ–°æµªçƒ­ç‚¹", news_list
    except Exception as e:
        print(f"æ–°æµªæ–°é—»è·å–å¤±è´¥: {e}")
    return None

def get_thepaper_news():
    """è·å–æ¾æ¹ƒæ–°é—» - æƒå¨åª’ä½“è§‚ç‚¹[citation:9]"""
    try:
        # æ¾æ¹ƒæ–°é—»é€šå¸¸æœ‰æ·±åº¦çš„æ—¶æ”¿å’Œç¤¾ä¼šæ–°é—»[citation:9]
        # æ­¤å¤„ä½¿ç”¨é€šç”¨APIå¹¶æ¨¡æ‹Ÿæ¾æ¹ƒé£æ ¼
        url = "https://api.oioweb.cn/api/news"
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            data = response.json()
            if 'result' in data:
                news_list = []
                for item in data['result'][:5]:
                    title = item.get('title', '').strip()
                    if title and any(word in title for word in ['è¯„è®º', 'è§‚å¯Ÿ', 'åˆ†æ', 'æ—¶è¯„']):
                        news_list.append((title, ""))
                if news_list:
                    return "ğŸ’¬ æ¾æ¹ƒè§‚ç‚¹", news_list
    except Exception as e:
        print(f"æ¾æ¹ƒæ–°é—»è·å–å¤±è´¥: {e}")
    return None

def get_tencent_news():
    """è·å–è…¾è®¯æ–°é—»çƒ­ç‚¹[citation:5][citation:10]"""
    try:
        # è…¾è®¯æ–°é—»åŒ…å«å¹¿æ³›çš„å›½å†…å›½é™…åŠæ°‘ç”Ÿæ–°é—»[citation:5][citation:10]
        url = "https://api.oioweb.cn/api/news"
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            data = response.json()
            if 'result' in data:
                news_list = []
                count = 0
                for item in data['result']:
                    if count >= 5:
                        break
                    title = item.get('title', '').strip()
                    if title:
                        news_list.append((title, item.get('hot', '')))
                        count += 1
                return "ğŸŒ è…¾è®¯æ–°é—»", news_list
    except Exception as e:
        print(f"è…¾è®¯æ–°é—»è·å–å¤±è´¥: {e}")
    return None

# ==================== æ ¸å¿ƒæ–°å¢ï¼šè‡ªåŠ¨åˆ†ç±»å‡½æ•° ====================

def categorize_news(title):
    """æ ¹æ®æ ‡é¢˜å…³é”®è¯å°†æ–°é—»è‡ªåŠ¨åˆ†ç±»"""
    title_lower = title.lower()
    
    # å®šä¹‰åˆ†ç±»å…³é”®è¯
    international_keywords = ['ç¾å›½', 'ä¿„ç½—æ–¯', 'æ¬§ç›Ÿ', 'å›½é™…', 'è”åˆå›½', 'å¤–äº¤', 'å…³ç¨', 'ä»¥å†›', 'ä¼Šæœ—']
    domestic_keywords = ['ä¸­å¤®', 'å›½å†…', 'æˆ‘å›½', 'ä¸­å›½', 'ä¹ è¿‘å¹³', 'æå¼º', 'æ”¿å', 'äººå¤§']
    livelihood_keywords = ['æ°‘ç”Ÿ', 'åŒ»ä¿', 'å°±ä¸š', 'ç¤¾ä¿', 'ä½æˆ¿', 'æ•™è‚²', 'åŒ»ç–—', 'å‡ºè¡Œ', 'é£Ÿå“', 'å®‰å…¨']
    tech_keywords = ['ç§‘æŠ€', 'äººå·¥æ™ºèƒ½', 'AI', 'åˆ›æ–°', 'æ•°å­—', 'æ™ºèƒ½', '5G', 'èŠ¯ç‰‡', 'èˆªå¤©']
    career_keywords = ['èŒä¸š', 'å°±ä¸š', 'æ‹›è˜', 'èŒåœº', 'è–ªèµ„', 'åŠ³åŠ¨æ³•', 'åŸ¹è®­', 'ç»æµ', 'å¸‚åœº', 'æ¶ˆè´¹']
    
    if any(keyword in title_lower for keyword in international_keywords):
        return "å›½é™…"
    elif any(keyword in title_lower for keyword in domestic_keywords):
        return "å›½å†…"
    elif any(keyword in title_lower for keyword in livelihood_keywords):
        return "æ°‘ç”Ÿ"
    elif any(keyword in title_lower for keyword in tech_keywords):
        return "ç§‘æŠ€"
    elif any(keyword in title_lower for keyword in career_keywords):
        return "èŒä¸š"
    else:
        return "ç»¼åˆ"  # é»˜è®¤åˆ†ç±»

def get_all_hot_news():
    """ä¸»å‡½æ•°ï¼šè·å–æ‰€æœ‰æ–°é—»å¹¶è‡ªåŠ¨åˆ†ç±»"""
    platforms = [
        ("äººæ°‘ç½‘", get_people_daily),
        ("ç™¾åº¦çƒ­æœ", get_baidu_hot),
        ("ä»Šæ—¥çƒ­æ¦œ", get_today_hotlist),
        ("æ–°æµªæ–°é—»", get_sina_news),
        ("æ¾æ¹ƒæ–°é—»", get_thepaper_news),
        ("è…¾è®¯æ–°é—»", get_tencent_news)
    ]
    
    # åˆå§‹åŒ–åˆ†ç±»å­—å…¸
    categorized_news = {
        "å›½é™…": [],
        "å›½å†…": [],
        "æ°‘ç”Ÿ": [],
        "ç§‘æŠ€": [],
        "èŒä¸š": [],
        "ç»¼åˆ": []
    }
    
    success_count = 0
    
    for platform_name, platform_func in platforms:
        print(f"æ­£åœ¨è·å– {platform_name}...")
        result = platform_func()
        
        if result:
            section_title, news_list = result
            print(f"  âœ“ è·å–åˆ° {len(news_list)} æ¡æ–°é—»")
            
            for title, hot in news_list:
                category = categorize_news(title)
                hot_text = f" ({hot})" if hot else ""
                categorized_news[category].append(f"â€¢ {title}{hot_text}")
            
            success_count += 1
        else:
            print(f"  âœ— è·å–å¤±è´¥")
        time.sleep(0.5)  # ç¤¼è²Œå»¶è¿Ÿ
    
    # æ„å»ºåˆ†ç±»è¾“å‡º
    all_news = []
    for category, items in categorized_news.items():
        if items:  # åªæ˜¾ç¤ºæœ‰å†…å®¹çš„åˆ†ç±»
            all_news.append(f"\nã€{category}æ–°é—»ã€‘")
            # æ¯ä¸ªåˆ†ç±»ä¸‹æœ€å¤šæ˜¾ç¤º8æ¡ï¼Œé¿å…é‚®ä»¶è¿‡é•¿
            for item in items[:8]:
                all_news.append(f"  {item}")
    
    return "\n".join(all_news), success_count

# é‚®ä»¶å‘é€å‡½æ•° (ä¿æŒä¸å˜ï¼Œä½†é‚®ä»¶æ ‡é¢˜å¯æ›´æ–°ä¸ºâ€œåˆ†ç±»çƒ­ç‚¹æ–°é—»æ—¥æŠ¥â€)
# ä¸»æ‰§è¡Œå‡½æ•° (ä¿æŒä¸å˜)
